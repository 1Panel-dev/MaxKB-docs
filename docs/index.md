---
hide:
  - navigation
---

# Introduction

## What is MaxKB?

ðŸ’¬ MaxKB is a ready-to-use RAG chatbot that features robust workflow and MCP tool-use capabilities. It supports a wide range of mainstream large language models (LLMs), including DeepSeek-R1, Llama 3.3, OpenAI, among others.

MaxKB = Max Knowledge Base, it is a ready-to-use RAG chatbot that features robust workflow and MCP tool-use capabilities. MaxKB is widely applied in scenarios such as intelligent customer service, corporate internal knowledge bases, academic research, and education.

![Overview](/img/overview.png)
{: .browser-mockup }

## Features

- **Ready-to-Use**: Supports direct uploading of documents / automatic crawling of online documents, with features for automatic text splitting, vectorization, and RAG (Retrieval-Augmented Generation). This effectively reduces hallucinations in large models, providing a superior smart Q&A interaction experience.
- **Flexible Orchestration**: Equipped with a powerful workflow engine, function library and MCP tool-use, enabling the orchestration of AI processes to meet the needs of complex business scenarios.
- **Seamless Integration**: Facilitates zero-coding rapid integration into third-party business systems, quickly equipping existing systems with intelligent Q&A capabilities to enhance user satisfaction.
- **Model-Agnostic**: Supports various large models, including private models (such as DeepSeek, Llama, Qwen, etc.) and public models (like OpenAI, Claude, Gemini, etc.).

## Getting Help

Are you getting stuck anywhere? Here are a few links to places to look:

- For assistance with using MaxKB, you can seek guidance from both fellow MaxKB users and our experts on the [GitHub Discussions page](https://github.com/1Panel-dev/MaxKB/discussions/), or join the MaxKB community on [Discord](https://discord.gg/Bv7sR3UGZb)!.
- If you suspect you're running into a bug, please check the [GitHub issue tracker](https://github.com/1panel-dev/1panel/issues) to see if any existing issues match your problem. If not, feel free to fill out our bug report template and submit a new issue.
